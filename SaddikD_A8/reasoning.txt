Reasoning:
It is important to trim trailing spaces and newlines so the data is uniform to work with and proceed with the cleaning process.

It is important to identify the rows with missing values so they can be referenced prior to cleaning the data and throughout to understand if the missing values impact your area of focus and proceed to decide how to deal with them.

It is better to replace the missing values with “NA” than to remove the rows with missing values as we’d lose nearly 20% of our data which is significant, especially when the missing data may not be of particular interest when aggregating and visualizing the data later on. Additionally, rows that have null values can still contain important information, meaning that keeping them would result in a better representation of the overall dataset than if they were removed. Also, various python data processing and visualization packages, such as pandas, already have methods that can deal with null values, such as dropping them from a DataFrame (table), which does not impact the original csv file. This means that there is no need to remove the rows with null values in the actual csv file itself during the preprocessing stage, as it can always be removed in a more controlled way that preserves the original data better later on.

The mean, median, and mode should not be used as a condition as it is a measure of central tendency. Rather the interquartile ranges should be found and used to identify outliers. Using the mean would only be appropriate after the outliers are removed so it is a more accurate measure of the center of the data. Otherwise, it is important to use the median rather than the mean when working with the data as a replacement value for outliers. That is why the median was used as the replacement value.
